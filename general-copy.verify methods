I have a python 3.13+ program to run under windows 10+, whose main (but not sole) purpose
is to robustly and safely copy files between folder trees and set date-modified and
date-created timestamps so that the target files and source files are identical,
with features including
- different copy mechanisms depending on specific circumstances (eg file size, network-copies)
- different verification mechanisms depending on specific circumstances to ascertain that the content of the target is identical to the source
- rollback of the target to its orignal state should an issue arise
- set date-modified and date-created timestamps so the target appears identical to the source
- speed of copying and speed of verification (eg minimising numbers of parses of file contents for large or networked files)
- indication of progress during copying and verification

In the program main() references FolderCompareSync_class module which manages the primary tkinter UI.
FolderCompareSync_class module references FileCopyManager_class module to perform the safe and robust file copies and rollbacks etc.
FileTimestampManager_class is a utility to manage timestamps.
FolderCompareSync_Global_Imports module is at the top of nearly every module and exposes common shared global imports.
FolderCompareSync_Global_Constants module is at the top of nearly every module and exposes common global constants.

FolderCompareSync_class module has evolved over time and become a tad unwieldy for a developer to read and maintain.
I wish to retain the great features provided by the module, but change or re-write it to
- simplify its structure only where reasonable and safe to do so whilst (mandatoryily) maintaining its features,
with a view to making it easy for a developer to read and maintain
- replace the copy and verify mechanisms with new ones, per the attached specification,
which broadly speaking involves the copy/verify methodologies below.

Mandatory Requirements:
R.1: safe copying with notification and status returns if errors and/or cancelled by user 
R.2: copying of metadata including date-created and date-modified (and/or allowance for setting it afterward)
R.3: efficient (fast) copying
R.4: progress updates via tinker
R.5: very efficient (fast) verification to guarentee identical file contents and
R.6: well named Global Parameters controlling threshold for sizing and for chunked (or windowing) copying and verification, etc
R.7: safety of target files, where if a copy or verify fails, guarantee a rollback of the target file to its original state
R.8: a replacement FileCopyManager_class module must be as close as possible to "drop-in compatible" with the old module
R.9: well commented code both at a function level and as approproate at code block level

A) "DIRECT" copy:  Local HDD -> HDD (NTFS, on same machine)
-----------------------------------------------------------
Use when: 
- both source and target files are on SSD or HDD on the same machine, i.e. no network drive letters, and/or
- source file size is less than a specified size in a nominated global constant
Method:
1. Copy first
1.1. Copy using a native copy with progress/callbacks: Windows native CopyFileExW API (via ctypes) because it:
- Does the actual copy using the OS (fast, kernel-level, buffered).
- Preserves metadata
- Crucially: accepts a callback function that Windows calls periodically with progress info.
- That callback gives you Total file size, Bytes copied so far, Whether the copy is paused or cancelled etc 
So, for local drive-to-drive copies (both HDDs, SSDs, or mixed), CopyFileExW is preferred because we
want a fast windows-optimized we copy function which facilitates a progress bar during the copy.

2. Verify with a windowed mmap compare approach.
2.1 In the pre-copy UI, have 3 mutually exclusive radio buttons
(i) verify no files
(ii) verify every file after each copy (the default), and 
(iii) verify only files < {a specified size in a nominated global constant, notionally 1GB} after each copy 

2.2 After copying, walk the source and target files in fixed-size mmap windows (e.g., 8–64 MiB, based on a clearly named global constant), 
comparing windowed chunks, (i.e. omitting but leaving provision for a hashing scheme in terms of comments to "place hashing code here")
and compare each window during the windowed mmap compare (perhaps this approach permits early failing if a window mismatch occurs).
Fallback: if a mmap window read fails (e.g., on exotic FS or a glittch of some kind), then
automatically fall back to plain buffered compare for that window.
This gives OS-paged reads (4 KiB pages) without loading the whole file, works well on memory-constrained PCs,
and is faster than single read() the entire file into Python buffers for large files, as well as avoiding an "==" on
full file bytes objects for big files which would force full file reads/materialization in RAM and can thrash memory.

2.3 If later in the development cycle want to implement a hash method (perhaps ?blake3?
then refer B.1.2 below and use the same type of hash), allow in the structure provision for computing the source hash during
the windowed mmap verify and then with post-copy target (copied using CopyFileExW) separately compute the target hash
with a separate windowed mmap parse of the closed-then-reopened target, and then compare the hashes to verify identical content. 

2.4 Progress bar: advance by the window size at each window compare - should be easy to wire into the UI eg tkinter.

B) "STAGED" copy: Across networks / NAS / SMB
---------------------------------------------
Use when: 
- either source or target file uses a network drive letter, and/or
- source file size is >= a specified size in a nominated global constant
Method:
1. Copy first
1.1. Copy using (non-mmap) chunked I/O with chunks of size approriate to network file copying and based on a clearly named global constant
1.1.1 Over networks/SMB/NAS, we could still use CopyFileExW (Windows lets it stream), but will not do so
1.1.2 SINCE in this networking case the CopyFileExW method requires an additional costly-for-large-networked-files full-file-read:
[1. read source, 2. write target, 3. re-read-source for verify, 4. re-read-target for verify, 5. compare computed hash]
vs chunked I/O copying whilst progressively calculating the source hash, which has significant less data transfer 
[1. read source and calculate hash during copying chunks, 2. write target, 3. re-read-target for verify, 4. compare computed hash]

1.2 during copying of source->target, perform progressive calculation of the source hash using ?blake3?
(?BLAKE3? was said to be much faster than SHA-512?) which may be the fastest hasher on a >=5yo cpu given that an aim is
to ensure the copied target file has content identical to the source.

2. Verify with chunked I/O
2.1 In the pre-copy UI, have 3 mutually exclusive radio buttons
(i) verify no files
(ii) verify every file after each copy (the default), and 
(iii) verify only files < {a specified size in a nominated global constant, notionally 1GB} after each copy 

2.3 For post-copy hashing calculation of the target, prefer buffered chunked I/O over mmap for
target verification (e.g., 1–8 MiB chunks based on a clearly named global constant) to avoid pathological page-fault latency over the network stack.
Then compare the hashes to verify identical content. 

2.4 Progress bar: advance by the window size after each compare window; easy to wire into our own UI eg tkinter.
